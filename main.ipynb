{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e746c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "\n",
    "sys.path.append('./objectDetectionModule/')\n",
    "from objectDetectionModule.model import SSD300, MultiBoxLoss\n",
    "from datasets import PascalVOCDataset\n",
    "from utils import *\n",
    "\n",
    "import functions as fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa23bfa",
   "metadata": {},
   "source": [
    "# train model and hyperparameter define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'aquarium':1\n",
    "         ,'bottle':2\n",
    "         ,'bowl':3\n",
    "         ,'box':4\n",
    "         ,'bucket':5\n",
    "         ,'plastic_bag':6\n",
    "         ,'plate':7\n",
    "         ,'styrofoam':8\n",
    "         ,'tire':9\n",
    "         ,'toilet':10\n",
    "         ,'tub':11\n",
    "         ,'washing_machine':12\n",
    "         ,'water_tower':13\n",
    "         ,'background':0}\n",
    "\n",
    "# Data parameters\n",
    "data_folder = './dataSet/train_cdc/train_images/'  # folder with data files\n",
    "keep_difficult = True  # use objects considered difficult to detect?\n",
    "\n",
    "# Model parameters\n",
    "# Not too many here since the SSD300 has a very specific structure\n",
    "n_classes = len(label_map)  # number of different types of objects\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Learning parameters\n",
    "checkpoint = None  # path to model checkpoint, None if none\n",
    "batch_size = 8  # batch size\n",
    "iterations = 120000  # number of iterations to train\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "print_freq = 200  # print training status every __ batches\n",
    "lr = 1e-3  # learning rate\n",
    "decay_lr_at = [80000, 100000]  # decay learning rate after these many iterations\n",
    "decay_lr_to = 0.1  # decay learning rate to this fraction of the existing learning rate\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay\n",
    "grad_clip = None  # clip if gradients are exploding, which may happen at larger batch sizes (sometimes at 32) - you will recognize it by a sorting error in the MuliBox loss calculation\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param model: model\n",
    "    :param criterion: MultiBox loss\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables dropout\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "    lossList = []\n",
    "    # Batches\n",
    "    for i, (images, boxes, labels, _) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        images = images.to(device)  # (batch_size (N), 3, 300, 300)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "\n",
    "        # Forward prop.\n",
    "        predicted_locs, predicted_scores = model(images)  # (N, 8732, 4), (N, 8732, n_classes)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n",
    "        lossList.append(loss.item())\n",
    "        # Backward prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer, grad_clip)\n",
    "\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(train_loader),\n",
    "                                                                  batch_time=batch_time,\n",
    "                                                                  data_time=data_time, loss=losses))\n",
    "    del predicted_locs, predicted_scores, images, boxes, labels  # free some memory since their histories may be stored\n",
    "    return sum(lossList) / len(lossList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992adc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    global start_epoch, label_map, epoch, checkpoint, decay_lr_at\n",
    "\n",
    "    # Initialize model or load checkpoint\n",
    "    if checkpoint is None:\n",
    "        start_epoch = 0\n",
    "        model = SSD300(n_classes=n_classes)\n",
    "        # Initialize the optimizer, with twice the default learning rate for biases, as in the original Caffe repo\n",
    "        biases = list()\n",
    "        not_biases = list()\n",
    "        for param_name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if param_name.endswith('.bias'):\n",
    "                    biases.append(param)\n",
    "                else:\n",
    "                    not_biases.append(param)\n",
    "        optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': 2 * lr}, {'params': not_biases}],\n",
    "                                    lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
    "        model = checkpoint['model']\n",
    "        optimizer = checkpoint['optimizer']\n",
    "\n",
    "    # Move to default device\n",
    "    model = model.to(device)\n",
    "    criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    train_dataset = PascalVOCDataset(data_folder,\n",
    "                                     split='train',\n",
    "                                     keep_difficult=keep_difficult)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               collate_fn=train_dataset.collate_fn, num_workers=workers,\n",
    "                                               pin_memory=True)  # note that we're passing the collate function here\n",
    "\n",
    "    # Calculate total number of epochs to train and the epochs to decay learning rate at (i.e. convert iterations to epochs)\n",
    "    # To convert iterations to epochs, divide iterations by the number of iterations per epoch\n",
    "    # The paper trains for 120,000 iterations with a batch size of 32, decays after 80,000 and 100,000 iterations\n",
    "#     epochs = iterations // (len(train_dataset) // 32)\n",
    "    epochs = 500\n",
    "    decay_lr_at = [it // (len(train_dataset) // 32) for it in decay_lr_at]\n",
    "    lossList = []\n",
    "    # Epochs\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        # Decay learning rate at particular epochs\n",
    "        if epoch in decay_lr_at:\n",
    "            adjust_learning_rate(optimizer, decay_lr_to)\n",
    "\n",
    "        # One epoch's training\n",
    "        lossx = train(train_loader=train_loader,\n",
    "                  model=model,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  epoch=epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(epoch, model, optimizer)\n",
    "        lossList.append(lossx)\n",
    "        with open('./models/accu.pickle', 'wb') as f:\n",
    "            pickle.dump(lossList, f)\n",
    "        torch.save(model.state_dict(), './models/model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da12ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464367f6",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_color_map = {\n",
    "    'aquarium': '#e6194b',\n",
    "     'bottle': '#3cb44b',\n",
    "     'bowl': '#ffe119',\n",
    "     'box': '#0082c8',\n",
    "     'bucket': '#f58231',\n",
    "     'plastic_bag': '#911eb4',\n",
    "     'plate': '#46f0f0',\n",
    "     'styrofoam': '#f032e6',\n",
    "     'tire': '#d2f53c',\n",
    "     'toilet': '#fabebe',\n",
    "     'tub': '#008080',\n",
    "     'washing_machine': '#000080',\n",
    "     'water_tower': '#aa6e28',\n",
    "     'background': '#FFFFFF'\n",
    "    }\n",
    "\n",
    "rev_label_map = {1:'aquarium'\n",
    "                ,2:'bottle'\n",
    "                ,3:'bowl'\n",
    "                ,4:'box'\n",
    "                ,5:'bucket'\n",
    "                ,6:'plastic_bag'\n",
    "                ,7:'plate'\n",
    "                ,8:'styrofoam'\n",
    "                ,9:'tire'\n",
    "                ,10:'toilet'\n",
    "                ,11:'tub'\n",
    "                ,12:'washing_machine'\n",
    "                ,13:'water_tower'\n",
    "                ,0:'background'}\n",
    "\n",
    "label_map = {'aquarium':1\n",
    "         ,'bottle':2\n",
    "         ,'bowl':3\n",
    "         ,'box':4\n",
    "         ,'bucket':5\n",
    "         ,'plastic_bag':6\n",
    "         ,'plate':7\n",
    "         ,'styrofoam':8\n",
    "         ,'tire':9\n",
    "         ,'toilet':10\n",
    "         ,'tub':11\n",
    "         ,'washing_machine':12\n",
    "         ,'water_tower':13\n",
    "         ,'background':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data load\n",
    "path = './dataSet/test_cdc/test_images/'\n",
    "with open('./dataSet/test_cdc/datas.pickle', 'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "\n",
    "testDatas = []\n",
    "for i, j in enumerate(datas):\n",
    "    testDatas.append(path + datas[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters load\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint = './models/checkpoint_ssd300.pth.tar'\n",
    "checkpoint = torch.load(checkpoint)\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
    "model = checkpoint['model']\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Transforms\n",
    "resize = transforms.Resize((300, 300))\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ac998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(original_image, min_score, max_overlap, top_k, suppress=None):\n",
    "    \"\"\"\n",
    "    Detect objects in an image with a trained SSD300, and visualize the results.\n",
    "    :param original_image: image, a PIL Image\n",
    "    :param min_score: minimum threshold for a detected box to be considered a match for a certain class\n",
    "    :param max_overlap: maximum overlap two boxes can have so that the one with the lower score is not suppressed via Non-Maximum Suppression (NMS)\n",
    "    :param top_k: if there are a lot of resulting detection across all classes, keep only the top 'k'\n",
    "    :param suppress: classes that you know for sure cannot be in the image or you do not want in the image, a list\n",
    "    :return: annotated image, a PIL Image\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform\n",
    "    image = normalize(to_tensor(resize(original_image)))\n",
    "\n",
    "    # Move to default device\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Forward prop.\n",
    "    predicted_locs, predicted_scores = model(image.unsqueeze(0))\n",
    "\n",
    "    # Detect objects in SSD output\n",
    "    det_boxes, det_labels, det_scores = model.detect_objects(predicted_locs, predicted_scores, min_score=min_score,\n",
    "                                                             max_overlap=max_overlap, top_k=top_k)\n",
    "\n",
    "    # Move detections to the CPU\n",
    "    det_boxes = det_boxes[0].to('cpu')\n",
    "\n",
    "    # Transform to original image dimensions\n",
    "    original_dims = torch.FloatTensor(\n",
    "        [original_image.width, original_image.height, original_image.width, original_image.height]).unsqueeze(0)\n",
    "    det_boxes = det_boxes * original_dims\n",
    "\n",
    "    # Decode class integer labels\n",
    "    det_labels = [rev_label_map[l] for l in det_labels[0].to('cpu').tolist()]\n",
    "\n",
    "    # If no objects found, the detected labels will be set to ['0.'], i.e. ['background'] in SSD300.detect_objects() in model.py\n",
    "    if det_labels == ['background']:\n",
    "        # Just return original image\n",
    "        return 0\n",
    "\n",
    "    # Annotate\n",
    "    annotated_image = original_image\n",
    "    draw = ImageDraw.Draw(annotated_image)\n",
    "#     font = ImageFont.truetype(\"./calibril.ttf\", 15)\n",
    "\n",
    "    # Suppress specific classes, if needed\n",
    "#     for i in range(det_boxes.size(0)):\n",
    "#         if suppress is not None:\n",
    "#             if det_labels[i] in suppress:\n",
    "#                 continue\n",
    "\n",
    "#         # Boxes\n",
    "#         box_location = det_boxes[i].tolist()\n",
    "#         draw.rectangle(xy=box_location, outline=label_color_map[det_labels[i]])\n",
    "#         draw.rectangle(xy=[l + 1. for l in box_location], outline=label_color_map[\n",
    "#             det_labels[i]])  # a second rectangle at an offset of 1 pixel to increase line thickness\n",
    "        # draw.rectangle(xy=[l + 2. for l in box_location], outline=label_color_map[\n",
    "        #     det_labels[i]])  # a third rectangle at an offset of 1 pixel to increase line thickness\n",
    "        # draw.rectangle(xy=[l + 3. for l in box_location], outline=label_color_map[\n",
    "        #     det_labels[i]])  # a fourth rectangle at an offset of 1 pixel to increase line thickness\n",
    "\n",
    "        # Text\n",
    "#         text_size = font.getsize(det_labels[i].upper())\n",
    "#         text_location = [box_location[0] + 2., box_location[1] - text_size[1]]\n",
    "#         textbox_location = [box_location[0], box_location[1] - text_size[1], box_location[0] + text_size[0] + 4.,\n",
    "#                             box_location[1]]\n",
    "#         draw.rectangle(xy=textbox_location, fill=label_color_map[det_labels[i]])\n",
    "#         draw.text(xy=text_location, text=det_labels[i].upper(), fill='white',\n",
    "#                   font=font)\n",
    "    del draw\n",
    "    \n",
    "    return -1, det_boxes, det_labels\n",
    "#     return annotated_image, det_boxes, det_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalList = []\n",
    "for img_path in testDatas:\n",
    "    original_image = Image.open(img_path, mode='r')\n",
    "    original_image = original_image.convert('RGB')\n",
    "    outputs = detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200)\n",
    "    if outputs == 0:\n",
    "        continue\n",
    "    name = img_path.split('/')[-1]\n",
    "    \n",
    "    labelx = []\n",
    "    for i in outputs[2]:\n",
    "        labelx.append(label_map[i])\n",
    "    \n",
    "    loc = outputs[1].cpu().detach().numpy()\n",
    "    loc = loc.astype(int)\n",
    "    loc[:, 2] = loc[:, 2] - loc[:, 0]\n",
    "    loc[:, 3] = loc[:, 3] - loc[:, 1]\n",
    "    \n",
    "    cc = [name, labelx, loc]\n",
    "    finalList.append(cc)\n",
    "\n",
    "finalList2 = []\n",
    "for i in finalList:\n",
    "    ln = len(i[1])\n",
    "    l = np.array(i[1]).reshape(-1, 1)   # labelx\n",
    "    l2 = i[2]          # loc\n",
    "    l3 = [i[0]] * ln\n",
    "    l3 = np.array(l3).reshape(-1, 1)  # name\n",
    "    l4 = np.array(l3).reshape(-1, 1)\n",
    "    l5 = np.concatenate([l3, l, l2], axis=1)\n",
    "    finalList2.append(l5)\n",
    "    \n",
    "final3 = np.concatenate(finalList2, axis=0)\n",
    "n = final3.shape[0]\n",
    "ff = (np.zeros(n) + 0.99).reshape(-1, 1)\n",
    "final4 = np.concatenate([final3, ff], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1abbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.DataFrame(final4, columns=['image_filename', 'label_id', 'x', 'y', 'w', ' h', 'confidence'])\n",
    "dataFrame.to_csv('./outputs/output1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
